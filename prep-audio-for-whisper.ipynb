{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "289b0a22",
   "metadata": {},
   "source": [
    "# Install dependencies for Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "20db5e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (20230124)\n",
      "Requirement already satisfied: numpy in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from openai-whisper) (1.24.2)\n",
      "Requirement already satisfied: torch in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from openai-whisper) (2.0.0.dev20230220)\n",
      "Requirement already satisfied: tqdm in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from openai-whisper) (4.64.1)\n",
      "Requirement already satisfied: more-itertools in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from openai-whisper) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.19.0 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from openai-whisper) (4.26.1)\n",
      "Requirement already satisfied: ffmpeg-python==0.2.0 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from openai-whisper) (0.2.0)\n",
      "Requirement already satisfied: future in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
      "Requirement already satisfied: filelock in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from transformers>=4.19.0->openai-whisper) (3.9.0)\n",
      "Requirement already satisfied: requests in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from transformers>=4.19.0->openai-whisper) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from transformers>=4.19.0->openai-whisper) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from transformers>=4.19.0->openai-whisper) (2022.3.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from transformers>=4.19.0->openai-whisper) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from transformers>=4.19.0->openai-whisper) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from transformers>=4.19.0->openai-whisper) (0.12.1)\n",
      "Requirement already satisfied: networkx in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from torch->openai-whisper) (3.0rc1)\n",
      "Requirement already satisfied: typing-extensions in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from torch->openai-whisper) (4.4.0)\n",
      "Requirement already satisfied: sympy in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from torch->openai-whisper) (1.11.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from packaging>=20.0->transformers>=4.19.0->openai-whisper) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from requests->transformers>=4.19.0->openai-whisper) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from requests->transformers>=4.19.0->openai-whisper) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from requests->transformers>=4.19.0->openai-whisper) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from requests->transformers>=4.19.0->openai-whisper) (2022.9.24)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (from sympy->torch->openai-whisper) (1.2.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Users/bear/.pyenv/versions/3.9.14/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai-whisper\n",
    "pip install setuptools-rust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344597d",
   "metadata": {},
   "source": [
    "# (Optional) Installing latest version of Pytorch for M1 Mac\n",
    "Recent release added support for M1's GPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7aea0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cpu\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cpu/torch-2.0.0.dev20230220-cp39-none-macosx_11_0_arm64.whl (56.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading https://download.pytorch.org/whl/nightly/filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
      "Collecting typing-extensions\n",
      "  Downloading https://download.pytorch.org/whl/nightly/typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting sympy\n",
      "  Downloading https://download.pytorch.org/whl/nightly/sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx\n",
      "  Downloading https://download.pytorch.org/whl/nightly/networkx-3.0rc1-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting mpmath>=0.19\n",
      "  Downloading https://download.pytorch.org/whl/nightly/mpmath-1.2.1-py3-none-any.whl (532 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.6/532.6 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, typing-extensions, sympy, networkx, filelock, torch\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: networkx\n",
      "    Found existing installation: networkx 2.8.7\n",
      "    Uninstalling networkx-2.8.7:\n",
      "      Successfully uninstalled networkx-2.8.7\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.8.0\n",
      "    Uninstalling filelock-3.8.0:\n",
      "      Successfully uninstalled filelock-3.8.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "demisto-sdk 1.7.6 requires networkx<3.0.0,>=2.7.1, but you have networkx 3.0rc1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed filelock-3.9.0 mpmath-1.2.1 networkx-3.0rc1 sympy-1.11.1 torch-2.0.0.dev20230220 typing-extensions-4.4.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Users/bear/.pyenv/versions/3.9.14/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --pre --force-reinstall torch --index-url https://download.pytorch.org/whl/nightly/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29298c99",
   "metadata": {},
   "source": [
    "### SImple usage of Whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ff4977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 461M/461M [00:47<00:00, 10.1MiB/s]\n",
      "/Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages/whisper/transcribe.py:78: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hey I'm just gonna record this so when I get up in the morning I like to brush my teeth and then I'll take Bear out to potty but before that I like to make a pot of coffee and I use about 30 grams of ground Colombian coffee to then brew my coffee. After that I'm gonna go into my office and open up my computer and then I check my email and from my email I then move to my tickets to just kind of update them and get them going. Yeah that's about it.\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"small\")\n",
    "result = model.transcribe(\"process_audio.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d7f62d",
   "metadata": {},
   "source": [
    "You can add additional files to the playbook directory and run them through this example. Just replace `\"process_audio.wav\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d49e42",
   "metadata": {},
   "source": [
    "### Testing Glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "691cfdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['process_audio.mp3',\n",
       " 'process_audio.wav',\n",
       " 'process_audio.flac',\n",
       " 'process_audio.m4a']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "glob.glob(\"process_*.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e1440c",
   "metadata": {},
   "source": [
    "Here we are ensuring glob is going to find our files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567bfed",
   "metadata": {},
   "source": [
    "### Benchmark Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import whisper\n",
    "import glob\n",
    "print(\"Timeit running...\")\n",
    "for x in glob.glob(\"process_*.*\"):\n",
    "    result = timeit.timeit(f'import whisper; model = whisper.load_model(\"base.en\"); output = model.transcribe(\"{x}\", fp16=False)', number=20)\n",
    "    print(x, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc68211",
   "metadata": {},
   "source": [
    "In the section below we are using `timeit`, `whisper` and `glob` for a small and simple benchmark.\n",
    "`timeit` will run our source 20 times for each time we loop through the collection of files `glob` has found. Since timeit take a string of the source we want to run, we can easily use string formatting to \"inject\" each file from `glob` to be transcribed. \n",
    "\n",
    "Whisper checks to see if it can use fp16(floating point 16) or fp32(floating point 32). If fp16 is not available Whisper displays a warning each time we call it... Could get a little annoying so I've added `fp16=False` for my setup to suppress warnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ac802",
   "metadata": {},
   "source": [
    "### Chunking the audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86489696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydub in /Users/bear/.pyenv/versions/3.9.14/lib/python3.9/site-packages (0.25.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Users/bear/.pyenv/versions/3.9.14/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d1f2ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exporting chunk 0\n",
      "exporting chunk 1\n",
      "exporting chunk 2\n",
      "exporting chunk 3\n",
      "exporting chunk 4\n",
      "exporting chunk 5\n",
      "exporting chunk 6\n",
      "exporting chunk 7\n",
      "exporting chunk 8\n",
      "exporting chunk 9\n",
      "exporting chunk 10\n",
      "exporting chunk 11\n",
      "exporting chunk 12\n",
      "exporting chunk 13\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "def split(filepath):\n",
    "    sound = AudioSegment.from_wav(filepath)\n",
    "    return split_on_silence(\n",
    "        sound,\n",
    "        min_silence_len = 500,\n",
    "        silence_thresh = sound.dBFS - 16,\n",
    "        keep_silence = 250, # optional\n",
    "    )\n",
    "\n",
    "chunks = split(\"process_audio.wav\")\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"exporting chunk {i}\")\n",
    "    chunk.export(\n",
    "        f\"chunk_{i}.mp3\",\n",
    "        bitrate = \"192k\",\n",
    "        format = \"mp3\"\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2a773",
   "metadata": {},
   "source": [
    "In this section we're going to break the audio file in to chunk based on sections of silence. We'll need pydub, a library used for audio manipulation. \n",
    "\n",
    "Here we have a function `split` that takes in a file name. It creates an audio segment from the file and returns the chunks. \n",
    "\n",
    "\n",
    "In `split_on_silence` it looks for a minimum length of silence to split up the audio file. `silence_thresh` is a threshold of silence is defined as. If its within the range defined it will be considered silence. The call to `sound.dBFS` is the maximum possible loudness the sound could be - 16.\n",
    "\n",
    "\n",
    "`keep_silence` is the amount of time in milliseconds that will be added to the split audio file in the beginning and end. We'll want to use this to make sure we don't miss anything.\n",
    "\n",
    "\n",
    "So we split the audio file. Our final step with chunking is exporting our newly created chunks. In this block it loops over the chunks, pull one off each iteration. It prints a message letting us know whats happening. The files is names chunk_X.mp3 with X being the `i` or the index of our loop. Bitrate is set to 192k, which is an OK bitrate for an mp3. And ofcourse it exports it as an mp3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cebf56",
   "metadata": {},
   "source": [
    "### What is Bitrate\n",
    "Bitrate refers to the amount of information in an audio file per second. It tells you how much detail and quality you can expect from the sound. A higher bit rate means more information and better sound quality, while a lower bit rate means less information and lower quality sound."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a694e",
   "metadata": {},
   "source": [
    "### Running the Chunks through Whisper!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8adffd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk_0.mp3  Hey, I'm just going to record this. So when I get up in the morning, I like to brush my teeth and then\n",
      "chunk_1.mp3  I'll take bear out to potty.\n",
      "chunk_2.mp3  But before that I like to make a pot of coffee\n",
      "chunk_3.mp3  um\n",
      "chunk_4.mp3  And I use about 30 grams.\n",
      "chunk_5.mp3  of ground Colombian coffee.\n",
      "chunk_6.mp3  to then brew my coffee.\n",
      "chunk_7.mp3  After that\n",
      "chunk_8.mp3  I'm gonna go into my office.\n",
      "chunk_9.mp3  and open up my computer and then I check my email.\n",
      "chunk_10.mp3  and from my email\n",
      "chunk_11.mp3  I then move to my tickets to just kind of update them and get them going\n",
      "chunk_12.mp3  Um\n",
      "chunk_13.mp3  Yeah, that's about it.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "model = whisper.load_model(\"base.en\")\n",
    "chunks = glob.glob(\"chunk_*.mp3\")\n",
    "for chunk in sorted(chunks, key=lambda s: int(re.search(r'\\d+', s).group())):\n",
    "    results = model.transcribe(chunk, fp16=False)\n",
    "    print(chunk, results[\"text\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdfbaaa",
   "metadata": {},
   "source": [
    "Ahhhh we've finally made it to this point! Now we take our chunks and feed them to Whisper. Sorted out of the box does a decent job sorting our files name returned from `glob` but it needs a little help. `key` takes a function or a callable to then call that function on each element in the list prior to comparing for the sort. \n",
    "\n",
    "Example: If the string is lowercase it will be placed befor an uppercase word.\n",
    "```python\n",
    ">> sorted(\"This is a test string from Andrew\".split(), key=str.lower)\n",
    "['a', 'Andrew', 'from', 'is', 'string', 'test', 'This']\n",
    "```\n",
    "\n",
    "```python\n",
    "lambda s: int(re.search(r'\\d+', s).group())\n",
    "```\n",
    "lambda is a short hand function for python. `s` is the parameter like name in `def yell(name)`. So `s` will be the name of the file ex `chunk_0.mp3`. It uses regex to search the input value of `s`. `re.search(r'\\d+',s).group()` searches for the digit in the file name and returns it at an int. Sorted will use that result and place the item in the proper order.\n",
    "\n",
    "Heres a little example to help break down the regex\n",
    "```python\n",
    "import re\n",
    "l = [\"chunk_0.mp3\", \"chunk_10.mp3\", \"chunk_5.mp3\"]\n",
    "for x in l:\n",
    "  y = int(re.search(r'\\d+', x).group())\n",
    "  print(y)\n",
    "```\n",
    "Output:\n",
    "```\n",
    "0\n",
    "10\n",
    "5\n",
    "```\n",
    "\n",
    "Once we have the chunks sorted its just a matter running the chunk through Whisper.\n",
    "\n",
    "**Results**\n",
    "```\n",
    "chunk_0.mp3  Hey, I'm just going to record this. So when I get up in the morning, I like to brush my teeth and then\n",
    "chunk_1.mp3  I'll take bear out to potty.\n",
    "chunk_2.mp3  But before that I like to make a pot of coffee\n",
    "chunk_3.mp3  um\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
